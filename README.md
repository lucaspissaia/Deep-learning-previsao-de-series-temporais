# üöÄ Deep Learning para Previs√£o de S√©ries Temporais (Mercado de A√ß√µes)

Este reposit√≥rio cont√©m o Trabalho Final de Deep Learning do **MBA em Data Science & AI da FIAP (10DTSR)**.

Como parte de uma simula√ß√£o da equipe de cientistas de dados da *Quantum Finance*, o objetivo deste projeto foi desenvolver e comparar diferentes arquiteturas de Deep Learning para prever sinais de **'Compra' (1) ou 'Venda' (0)** para a√ß√µes do mercado brasileiro, com base no hist√≥rico de 15 dias de negocia√ß√£o.

O projeto n√£o se concentrou em encontrar um √∫nico "melhor modelo", mas sim em uma **an√°lise experimental** iterativa, testando diferentes abordagens de modelagem e engenharia de features em diferentes ativos (VALE3, PETR4, BBAS3, CSNA3).

---

## üèõÔ∏è Metodologia Experimental

A performance de cada modelo foi avaliada em duas frentes:
1.  **Acur√°cia Estat√≠stica:** Utilizando `classification_report` (Acur√°cia, Precis√£o, Recall, F1-Score) para medir a precis√£o da classifica√ß√£o.
2.  **Resultado Financeiro:** Utilizando uma fun√ß√£o de `backtest` para simular o retorno financeiro (crescimento do patrim√¥nio) ao seguir os sinais do modelo.

### 1. (VALE3) - Baseline: Modelos Sequenciais Puros
O primeiro experimento estabeleceu uma linha de base. Testamos tr√™s arquiteturas de Deep Learning usando *apenas* a sequ√™ncia de 15 dias de pre√ßos (normalizados como retornos) como entrada.

* **Modelos:** CNN 1D, RNN Simples, LSTM.
* **Resultados (Acur√°cia):** RNN (~88%) e LSTM (~89%) foram muito superiores √† CNN 1D (~69%), provando sua capacidade de capturar tend√™ncias sequenciais.
* **Resultados (Backtest):** Uma descoberta cr√≠tica. **A maior acur√°cia n√£o levou ao lucro.** Todos os modelos tiveram um resultado financeiro pr√≥ximo de zero (break-even).

### 2. (PETR4) - Modelos de Entrada Dupla (Sequ√™ncia + Features)
A hip√≥tese seguinte foi que a sequ√™ncia de pre√ßos por si s√≥ era insuficiente. Neste experimento, enriquecemos os modelos com *features* de an√°lise t√©cnica.

* **Modelos:** Arquiteturas de entrada dupla (CNN 1D, RNN, LSTM) que recebiam:
    1.  A sequ√™ncia de 15 dias de pre√ßos.
    2.  Um vetor de *features* (M√©dias M√≥veis, Retornos/Momentum, Volatilidade).
* **Resultados (Acur√°cia):** Acur√°cia manteve-se alta (~87%).
* **Resultados (Backtest):** **Um salto dr√°stico de performance.** A adi√ß√£o de features de an√°lise t√©cnica tornou os modelos lucrativos, com o `CNN1D + Features` gerando o melhor retorno (quase R$ 6.000 de lucro no per√≠odo de teste).

### 3. (BBAS3) - Modelos H√≠bridos (RNN + MLP)
Aqui, testamos se uma arquitetura h√≠brida (onde um "ramo" RNN processa a sequ√™ncia e um "ramo" MLP processa as *features* tabelares) aprenderia de forma mais eficaz.

* **Modelos:**
    1.  MLP (apenas features).
    2.  RNN (apenas sequ√™ncia).
    3.  H√≠brido (RNN + MLP) com aprendizado conjunto.
* **Resultados (Acur√°cia):** O modelo H√≠brido teve a maior acur√°cia estat√≠stica (~91%).
* **Resultados (Backtest):** Novamente, a maior acur√°cia n√£o venceu. O modelo `MLP (apenas features)` foi o mais lucrativo. O H√≠brido (e o RNN puro) tiveram preju√≠zo, sugerindo que, para este ativo, a sequ√™ncia de pre√ßos pode ter adicionado *ru√≠do* ou redund√¢ncia √†s features.

### 4. (CSNA3) - Vis√£o Computacional (CNN 2D com Imagens)
A etapa final testou uma abordagem completamente diferente: tratar o problema como Vis√£o Computacional.

* **Modelo:** Uma CNN 2D (rede convolucional de imagens).
* **Entrada:** Imagens (gr√°ficos de barras) representando os √∫ltimos 15 dias de pre√ßo.
* **Resultados (Acur√°cia):** Excelente acur√°cia (~88%) e m√©tricas de precis√£o/recall muito equilibradas.
* **Resultados (Backtest):** **O melhor resultado financeiro de todo o projeto.** O modelo de CNN 2D, treinado nas imagens, gerou o maior retorno de patrim√¥nio, capturando padr√µes visuais que os modelos sequenciais/tabelares n√£o identificaram.

---

## üí° Principais Conclus√µes

1.  **Acur√°cia Estat√≠stica ‚â† Lucratividade:** A principal li√ß√£o do projeto. Modelos com acur√°cia mais baixa (mas que "acertavam nos momentos certos") foram consistentemente mais lucrativos no backtest do que modelos com acur√°cia mais alta.
2.  **Engenharia de Features √© Crucial:** A adi√ß√£o de features de an√°lise t√©cnica (visto em PETR4) foi o fator que transformou modelos de *break-even* em modelos lucrativos. A riqueza das *features* provou ser t√£o importante quanto a arquitetura do modelo.
3.  **N√£o existe "Melhor Modelo" √önico:** A performance variou drasticamente entre os ativos e as abordagens. O modelo de imagens (CNN 2D) foi o campe√£o na CSNA3, enquanto um modelo de entrada dupla (CNN 1D + Features) foi o melhor para a PETR4.

---

## üõ†Ô∏è Stack Tecnol√≥gica

* **Linguagem:** Python
* **Bibliotecas de Deep Learning:** TensorFlow, Keras
* **Bibliotecas de Dados:** Pandas, NumPy, Scikit-learn (para pr√©-processamento, m√©tricas e *class weights*)
* **Visualiza√ß√£o:** Matplotlib, Seaborn
* **Ambiente:** Google Colab

## üë• Autores

* Erika Koyanagui
* Fabio Asnis Campos da Silva
* Lucas Huber Pissaia
* Matheus Raeski
